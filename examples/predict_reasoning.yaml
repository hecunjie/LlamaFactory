### model
model_name_or_path: /mnt/tidal-alsh01/dataset/zeus/hecunjie/train_outputs/latent_thinking_gsm8k/checkpoint-300

### method
stage: sft
do_predict: true
finetuning_type: full  # 如果是 LoRA，请改为 lora 并添加 adapter_name_or_path

### dataset
eval_dataset: reasoning_test_gsm8k
template: qwen
cutoff_len: 1024
# max_samples: 50
overwrite_cache: true
preprocessing_num_workers: 16

### output
output_dir: /mnt/tidal-alsh01/dataset/zeus/hecunjie/train_outputs/latent_thinking_gsm8k/predict
overwrite_output_dir: true

### eval
per_device_eval_batch_size: 2
predict_with_generate: true
ddp_timeout: 180000000
